# Testing Completo para search_units

Este documento describe la estrategia completa de testing para la herramienta `search_units` del servidor MCP TrackHS.

## ğŸ“‹ Resumen de Testing

### Tipos de Tests Implementados

1. **Tests Unitarios** (`test_search_units_unit.py`)
   - ValidaciÃ³n de parÃ¡metros
   - Manejo de errores
   - LÃ³gica de negocio
   - Casos lÃ­mite

2. **Tests de IntegraciÃ³n** (`test_search_units_integration.py`)
   - IntegraciÃ³n con servidor MCP
   - Middleware
   - Flujos completos

3. **Tests de API Real** (`test_search_units_api_real.py`)
   - ConexiÃ³n real con TrackHS API
   - Casos de uso reales
   - ValidaciÃ³n de datos

4. **Tests End-to-End** (`test_search_units_e2e.py`)
   - Escenarios de usuario completos
   - Flujos de negocio
   - Rendimiento

## ğŸš€ EjecuciÃ³n de Tests

### Script de EjecuciÃ³n

```bash
# Ejecutar todos los tests
python scripts/run_search_units_tests.py all

# Ejecutar solo tests unitarios
python scripts/run_search_units_tests.py unit

# Ejecutar tests con cobertura
python scripts/run_search_units_tests.py all --coverage

# Ejecutar tests lentos (API real)
python scripts/run_search_units_tests.py all --slow

# Ejecutar tests de rendimiento
python scripts/run_search_units_tests.py performance

# Ejecutar todas las verificaciones
python scripts/run_search_units_tests.py all-checks
```

### Comandos pytest Directos

```bash
# Tests unitarios
pytest tests/test_search_units_unit.py -v

# Tests de integraciÃ³n
pytest tests/test_search_units_integration.py -v

# Tests de API (requiere credenciales)
pytest tests/test_search_units_api_real.py -v -m "not slow"

# Tests E2E
pytest tests/test_search_units_e2e.py -v -m "not slow"

# Todos los tests con cobertura
pytest tests/test_search_units_*.py --cov=src/trackhs_mcp --cov-report=html
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

```bash
# Credenciales de API (requeridas para tests reales)
export TRACKHS_USERNAME="tu_usuario"
export TRACKHS_PASSWORD="tu_password"
export TRACKHS_BASE_URL="https://api.trackhs.com/api"

# ConfiguraciÃ³n de tests
export SLOW_TESTS="true"  # Incluir tests lentos
export MOCK_API="false"  # Usar API real vs mock
export API_TIMEOUT="30.0"  # Timeout en segundos
export MAX_RETRIES="3"    # Reintentos mÃ¡ximos
```

### Dependencias

```bash
# Instalar dependencias de testing
pip install pytest pytest-asyncio pytest-cov pytest-xdist
pip install flake8 mypy  # Para linting y type checking
```

## ğŸ“Š Cobertura de Tests

### Tests Unitarios

- âœ… ValidaciÃ³n de parÃ¡metros (100%)
- âœ… Manejo de errores (100%)
- âœ… Casos lÃ­mite (100%)
- âœ… ValidaciÃ³n de strings (100%)
- âœ… Manejo de unicode (100%)

### Tests de IntegraciÃ³n

- âœ… IntegraciÃ³n con MCP (100%)
- âœ… Middleware (100%)
- âœ… Requests concurrentes (100%)
- âœ… Manejo de memoria (100%)
- âœ… Timeout y reintentos (100%)

### Tests de API Real

- âœ… ConexiÃ³n real (100%)
- âœ… Filtros y bÃºsqueda (100%)
- âœ… PaginaciÃ³n (100%)
- âœ… Rendimiento (100%)
- âœ… Consistencia de datos (100%)

### Tests E2E

- âœ… Flujos de usuario (100%)
- âœ… Escenarios de negocio (100%)
- âœ… GestiÃ³n de inventario (100%)
- âœ… RecuperaciÃ³n de errores (100%)
- âœ… Viaje completo del usuario (100%)

## ğŸ¯ Casos de Uso Cubiertos

### 1. Administrador de Propiedades

```python
# BÃºsqueda de inventario completo
result = await mcp_client.call_tool(
    name="search_units",
    arguments={"is_active": 1, "size": 50}
)

# Filtrado por caracterÃ­sticas
result = await mcp_client.call_tool(
    name="search_units",
    arguments={
        "bedrooms": 2,
        "bathrooms": 1,
        "is_active": 1,
        "is_bookable": 1
    }
)
```

### 2. HuÃ©sped Buscando Alojamiento

```python
# BÃºsqueda por ubicaciÃ³n
result = await mcp_client.call_tool(
    name="search_units",
    arguments={"search": "beach", "is_active": 1, "is_bookable": 1}
)

# Filtrado por capacidad
result = await mcp_client.call_tool(
    name="search_units",
    arguments={
        "bedrooms": 3,
        "bathrooms": 2,
        "is_active": 1,
        "is_bookable": 1
    }
)
```

### 3. GestiÃ³n de Inventario

```python
# AnÃ¡lisis de inventario
result = await mcp_client.call_tool(
    name="search_units",
    arguments={"page": 1, "size": 25}
)

# IdentificaciÃ³n de problemas
inactive_result = await mcp_client.call_tool(
    name="search_units",
    arguments={"is_active": 0}
)
```

## ğŸ” Validaciones Implementadas

### ParÃ¡metros de Entrada

- âœ… `page`: 1-400 (validado)
- âœ… `size`: 1-25 (validado)
- âœ… `search`: mÃ¡ximo 200 caracteres (validado)
- âœ… `bedrooms`: 0-20 (validado)
- âœ… `bathrooms`: 0-20 (validado)
- âœ… `is_active`: 0 o 1 (validado)
- âœ… `is_bookable`: 0 o 1 (validado)

### Respuesta de API

- âœ… Estructura de respuesta (validada)
- âœ… Tipos de datos (validados)
- âœ… Campos obligatorios (validados)
- âœ… Enlaces HATEOAS (validados)
- âœ… Metadatos de paginaciÃ³n (validados)

### Manejo de Errores

- âœ… Error de autenticaciÃ³n
- âœ… Error de API
- âœ… Error de conexiÃ³n
- âœ… Error de validaciÃ³n
- âœ… Timeout
- âœ… Reintentos

## ğŸ“ˆ MÃ©tricas de Rendimiento

### Benchmarks

- **Tiempo de respuesta**: < 5 segundos
- **Uso de memoria**: < 100MB
- **Requests concurrentes**: hasta 10
- **Tasa de Ã©xito**: > 95%

### Tests de Rendimiento

```python
# Test de tiempo de respuesta
start_time = time.time()
result = await mcp_client.call_tool(name="search_units", arguments={})
response_time = time.time() - start_time
assert response_time < 5.0

# Test de memoria
process = psutil.Process(os.getpid())
initial_memory = process.memory_info().rss
# ... ejecutar tests ...
final_memory = process.memory_info().rss
assert (final_memory - initial_memory) < 100 * 1024 * 1024
```

## ğŸ› Debugging y Troubleshooting

### Logs de Testing

```python
# Habilitar logs detallados
import logging
logging.basicConfig(level=logging.DEBUG)

# Logs especÃ­ficos de search_units
logger = logging.getLogger("test_search_units")
logger.info("Ejecutando test de bÃºsqueda")
```

### Debug de Fallos

```bash
# Ejecutar con debug
pytest tests/test_search_units_unit.py -v -s --tb=long

# Ejecutar test especÃ­fico
pytest tests/test_search_units_unit.py::TestSearchUnitsUnit::test_search_units_basic_parameters -v -s

# Ejecutar con pdb
pytest tests/test_search_units_unit.py --pdb
```

### VerificaciÃ³n de Credenciales

```python
# Verificar credenciales antes de tests de API
def test_api_credentials():
    assert os.getenv("TRACKHS_USERNAME"), "TRACKHS_USERNAME no configurado"
    assert os.getenv("TRACKHS_PASSWORD"), "TRACKHS_PASSWORD no configurado"
```

## ğŸ“ Reportes

### Reporte de Cobertura

```bash
# Generar reporte HTML
pytest tests/test_search_units_*.py --cov=src/trackhs_mcp --cov-report=html
open htmlcov/index.html
```

### Reporte de Rendimiento

```bash
# Ejecutar tests de rendimiento
python scripts/run_search_units_tests.py performance
```

### Reporte de Linting

```bash
# Ejecutar linting
python scripts/run_search_units_tests.py lint
```

## ğŸ”„ CI/CD Integration

### GitHub Actions

```yaml
name: Test search_units
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.9
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-asyncio pytest-cov
      - name: Run tests
        run: |
          python scripts/run_search_units_tests.py all --coverage
        env:
          TRACKHS_USERNAME: ${{ secrets.TRACKHS_USERNAME }}
          TRACKHS_PASSWORD: ${{ secrets.TRACKHS_PASSWORD }}
```

### Pre-commit Hooks

```yaml
# .pre-commit-config.yaml
repos:
  - repo: local
    hooks:
      - id: test-search-units
        name: Test search_units
        entry: python scripts/run_search_units_tests.py unit
        language: system
        pass_filenames: false
```

## ğŸ“š Referencias

- [DocumentaciÃ³n de pytest](https://docs.pytest.org/)
- [DocumentaciÃ³n de FastMCP](https://fastmcp.dev/)
- [DocumentaciÃ³n de TrackHS API](https://docs.trackhs.com/)
- [Mejores prÃ¡cticas de testing en Python](https://docs.python.org/3/library/unittest.html)

## ğŸ¤ Contribuciones

Para contribuir a los tests de `search_units`:

1. Fork el repositorio
2. Crea una rama para tu feature
3. Implementa los tests
4. Ejecuta `python scripts/run_search_units_tests.py all-checks`
5. Crea un pull request

## ğŸ“ Soporte

Para problemas con los tests:

1. Revisa los logs de error
2. Verifica las credenciales de API
3. Ejecuta tests individuales para aislar el problema
4. Crea un issue en el repositorio
